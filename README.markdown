# Инструмент для записи, транскрибации аудио и отправки запросов к ИИ рабочая версия - 0.0.1.4

Этот проект представляет собой приложение с графическим интерфейсом, которое позволяет записывать аудио, транскрибировать его с использованием модели Whisper от OpenAI и отправлять полученный текст в качестве запроса к модели искусственного интеллекта для получения ответов. Программа идеально подходит для пользователей, которым нужно быстро преобразовать голосовые заметки или команды в текст и получить на их основе автоматические ответы от ИИ.

## Основные возможности

- **Запись аудио**: Используйте встроенный микрофон для записи голоса с функциями паузы, продолжения и очистки записи.
- **Транскрибация**: Автоматическое преобразование аудио в текст с помощью модели Whisper, оптимизированной для русской речи.
- **Интеграция с ИИ**: Отправка транскрибированного текста в качестве запроса к модели ИИ и отображение ответа в интерфейсе.
- **Удобный интерфейс**: Графический интерфейс на базе PyQt5 с интуитивно понятными кнопками управления.

## Требования к системе

- Операционная система: Windows, macOS или Linux.
- Работающий микрофон для записи аудио.
- Python 3.8 или выше.
- (Опционально) GPU для ускорения работы модели Whisper.
- Оперативной памяти >4гб

## Установка

Следуйте этим шагам, чтобы установить и настроить приложение:

1. **Клонируйте репозиторий**:
   ```
   git clone https://github.com/yourusername/yourrepo.git
   cd yourrepo
   ```

2. **Создайте виртуальное окружение**:
   ```
   python -m venv venv
   ```
   Активируйте его:
   - На Linux/macOS:
     ```
     source venv/bin/activate
     ```
   - На Windows:
     ```
     venv\Scripts\activate
     ```

3. **Установите зависимости**:
   Убедитесь, что вы находитесь в корневой директории проекта, и выполните:
   ```
   pip install -r requirements.txt
   ```
   Это установит все необходимые библиотеки, такие как `numpy`, `soundcard`, `openai-whisper`, `PyQt5` и другие.

## Использование

1. **Запустите приложение**:
   После установки зависимостей выполните:
   ```
   python main.py
   ```
   Откроется окно графического интерфейса.

2. **Работа с интерфейсом**:
   - **"Начать запись"**: Нажмите, чтобы начать запись аудио с микрофона.
   - **"Пауза"**: Приостановите запись, если нужно сделать перерыв.
   - **"Продолжить"**: Возобновите запись с того места, где остановились.
   - **"Очистить запись"**: Удалите текущую запись и начните заново.
   - **"Транскрибировать"**: Преобразуйте записанное аудио в текст. Результат отобразится в интерфейсе.
   - **"Отправить запрос"**: Отправьте транскрибированный текст модели ИИ и получите ответ.

## Пример работы

1. Нажмите "Начать запись" и произнесите: "Какая погода сегодня в Москве?"
2. Нажмите "Транскрибировать" — текст "Какая погода сегодня в Москве?" появится в поле.
3. Нажмите "Отправить запрос" — ИИ вернет ответ, например: "Сегодня в Москве ожидается солнечная погода, температура около 15°C."

## Примечания

- **Оборудование**: Убедитесь, что микрофон подключен и работает. Динамики не требуются, но могут быть полезны для проверки записи.
- **Производительность**: Модель Whisper требует значительных ресурсов. Использование GPU (например, с CUDA) ускорит транскрибацию. Без GPU процесс может занять больше времени.
- **Язык**: По умолчанию настроено распознавание русской речи. Для изменения языка откройте файл `audio_recorder.py` и измените параметр `language` в методе `transcribe` (например, на `"en"` для английского).
- **Технические детали**:
  - Переменная окружения `KMP_DUPLICATE_LIB_OK` установлена в `"TRUE"` для избежания конфликтов с Intel MKL.
  - PyTorch использует один поток для предотвращения перегрузки процессора.
  - При проблемах с Qt проверьте переменную окружения `QT_QPA_PLATFORM_PLUGIN_PATH`.

## Зависимости

Проект использует следующие библиотеки:
- `numpy` — для работы с массивами данных.
- `soundcard` — для записи аудио с микрофона.
- `openai-whisper` — для транскрибации аудио.
- `soundfile` — для обработки аудиофайлов.
- `torch` — для работы с моделью Whisper.
- `scipy` — для обработки сигналов.
- `PyQt5` — для создания графического интерфейса.
- `duckai` — для взаимодействия с моделью ИИ.

## Возможные улучшения

- Добавление поддержки нескольких языков в интерфейсе.
- Интеграция с облачными сервисами для ускорения транскрибации.
- Добавление функции сохранения аудио и текста.

Если у вас возникнут вопросы или проблемы, создайте issue в репозитории!